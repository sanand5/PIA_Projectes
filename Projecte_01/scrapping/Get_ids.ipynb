{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_soup(api_key, url):\n",
    "    params = {\n",
    "        'api_key': api_key,\n",
    "        'url': url,\n",
    "        'country_code': 'ES'  # Código de país para España\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://api.scraperapi.com/', params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return BeautifulSoup(response.text, 'html.parser')\n",
    "    else:\n",
    "        print(f'Error al obtener la página: {response.status_code}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_ids(soup):\n",
    "    ids_productos = set()\n",
    "    productos = soup.find_all('div', {'role': 'listitem', 'data-asin': True})\n",
    "    if productos:\n",
    "        for producto in productos:\n",
    "            id = producto.get('data-asin')\n",
    "            ids_productos.add(id)\n",
    "        return ids_productos\n",
    "    else: return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo IDs de la página 1...\n",
      "Obteniendo IDs de la página 2...\n",
      "Obteniendo IDs de la página 3...\n",
      "Obteniendo IDs de la página 4...\n",
      "Obteniendo IDs de la página 5...\n",
      "Obteniendo IDs de la página 6...\n",
      "Obteniendo IDs de la página 7...\n",
      "Obteniendo IDs de la página 8...\n",
      "No se encontraron IDs en la página 8. Terminando la recolección.\n",
      "Se guardaron 265 IDs de productos en 'ids.json'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_URL = \"https://www.amazon.es/s?k=\"\n",
    "API_KEY = '1d8a83a5b3d3bfb0e635d9319bf08dd0'\n",
    "QUERY = 'moviles'\n",
    "url_base = BASE_URL + QUERY\n",
    "page_number = 1\n",
    "ids_productos = set() \n",
    "\n",
    "while True:\n",
    "    print(f\"Obteniendo IDs de la página {page_number}...\")\n",
    "    url_pagina = f\"{url_base}&page={page_number}\"\n",
    "    soup = obtener_soup(API_KEY, url_pagina)\n",
    "    \n",
    "    if soup == None: break\n",
    "\n",
    "    ids_paguina = obtener_ids(soup)\n",
    "    if not ids_paguina:\n",
    "        print(f\"No se encontraron IDs en la página {page_number}. Terminando la recolección.\")\n",
    "        break\n",
    "    ids_productos.update(ids_paguina)\n",
    "    page_number += 1\n",
    "\n",
    "fichero = \"../res/ids.json\"\n",
    "os.makedirs(os.path.dirname(fichero), exist_ok=True)\n",
    "with open(fichero, \"w\") as f:\n",
    "    json.dump(list(ids_productos), f, indent=4)\n",
    "print(f\"Se guardaron {len(ids_productos)} IDs de productos en 'ids.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo IDs de la página 1 para la consulta 'moviles'...\n",
      "Obteniendo IDs de la página 2 para la consulta 'moviles'...\n",
      "Obteniendo IDs de la página 3 para la consulta 'moviles'...\n",
      "Obteniendo IDs de la página 4 para la consulta 'moviles'...\n",
      "Obteniendo IDs de la página 5 para la consulta 'moviles'...\n",
      "Obteniendo IDs de la página 6 para la consulta 'moviles'...\n",
      "Obteniendo IDs de la página 7 para la consulta 'moviles'...\n",
      "Obteniendo IDs de la página 8 para la consulta 'moviles'...\n",
      "No se encontraron IDs en la página 8 para la consulta 'moviles'. Terminando la recolección.\n",
      "Obteniendo IDs de la página 1 para la consulta 'smartphones'...\n",
      "Obteniendo IDs de la página 2 para la consulta 'smartphones'...\n",
      "Obteniendo IDs de la página 3 para la consulta 'smartphones'...\n",
      "Obteniendo IDs de la página 4 para la consulta 'smartphones'...\n",
      "Obteniendo IDs de la página 5 para la consulta 'smartphones'...\n",
      "Obteniendo IDs de la página 6 para la consulta 'smartphones'...\n",
      "Obteniendo IDs de la página 7 para la consulta 'smartphones'...\n",
      "Obteniendo IDs de la página 8 para la consulta 'smartphones'...\n",
      "Obteniendo IDs de la página 9 para la consulta 'smartphones'...\n",
      "No se encontraron IDs en la página 9 para la consulta 'smartphones'. Terminando la recolección.\n",
      "Obteniendo IDs de la página 1 para la consulta 'celulares'...\n",
      "Obteniendo IDs de la página 2 para la consulta 'celulares'...\n",
      "Obteniendo IDs de la página 3 para la consulta 'celulares'...\n",
      "Obteniendo IDs de la página 4 para la consulta 'celulares'...\n",
      "Obteniendo IDs de la página 5 para la consulta 'celulares'...\n",
      "Obteniendo IDs de la página 6 para la consulta 'celulares'...\n",
      "Obteniendo IDs de la página 7 para la consulta 'celulares'...\n",
      "Obteniendo IDs de la página 8 para la consulta 'celulares'...\n",
      "No se encontraron IDs en la página 8 para la consulta 'celulares'. Terminando la recolección.\n",
      "Obteniendo IDs de la página 1 para la consulta 'telefonos'...\n",
      "Obteniendo IDs de la página 2 para la consulta 'telefonos'...\n",
      "Obteniendo IDs de la página 3 para la consulta 'telefonos'...\n",
      "Obteniendo IDs de la página 4 para la consulta 'telefonos'...\n",
      "Obteniendo IDs de la página 5 para la consulta 'telefonos'...\n",
      "Obteniendo IDs de la página 6 para la consulta 'telefonos'...\n",
      "Obteniendo IDs de la página 7 para la consulta 'telefonos'...\n",
      "Obteniendo IDs de la página 8 para la consulta 'telefonos'...\n",
      "No se encontraron IDs en la página 8 para la consulta 'telefonos'. Terminando la recolección.\n",
      "Se guardaron 756 IDs de productos en 'ids.json'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "BASE_URL = \"https://www.amazon.es/s?k=\"\n",
    "API_KEY = '1d8a83a5b3d3bfb0e635d9319bf08dd0'\n",
    "QUERY = ['moviles', 'smartphones', 'celulares', 'telefonos']\n",
    "ids_productos = set()\n",
    "\n",
    "for query in QUERY:\n",
    "    url_base = BASE_URL + query\n",
    "    page_number = 1\n",
    "\n",
    "    while True:\n",
    "        print(f\"Obteniendo IDs de la página {page_number} para la consulta '{query}'...\")\n",
    "        url_pagina = f\"{url_base}&page={page_number}\"\n",
    "        soup = obtener_soup(API_KEY, url_pagina)\n",
    "\n",
    "        if soup is None:\n",
    "            break\n",
    "\n",
    "        ids_pagina = obtener_ids(soup)\n",
    "        if not ids_pagina:\n",
    "            print(f\"No se encontraron IDs en la página {page_number} para la consulta '{query}'. Terminando la recolección.\")\n",
    "            break\n",
    "\n",
    "        ids_productos.update(ids_pagina)\n",
    "        page_number += 1\n",
    "\n",
    "fichero = \"../res/ids.json\"\n",
    "os.makedirs(os.path.dirname(fichero), exist_ok=True)\n",
    "with open(fichero, \"w\") as f:\n",
    "    json.dump(list(ids_productos), f, indent=4)\n",
    "\n",
    "print(f\"Se guardaron {len(ids_productos)} IDs de productos en 'ids.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projecte01_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
