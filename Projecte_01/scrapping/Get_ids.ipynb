{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_soup(api_key, url):\n",
    "    params = {\n",
    "        'api_key': api_key,\n",
    "        'url': url,\n",
    "        'country_code': 'ES'  # Código de país para España\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://api.scraperapi.com/', params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return BeautifulSoup(response.text, 'html.parser')\n",
    "    else:\n",
    "        print(f'Error al obtener la página: {response.status_code}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_ids(soup):\n",
    "    ids_productos = set()\n",
    "    productos = soup.find_all('div', {'role': 'listitem', 'data-asin': True})\n",
    "    if productos:\n",
    "        for producto in productos:\n",
    "            id = producto.get('data-asin')\n",
    "            ids_productos.add(id)\n",
    "        return ids_productos\n",
    "    else: return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo IDs de la página 1...\n",
      "Obteniendo IDs de la página 2...\n",
      "Obteniendo IDs de la página 3...\n",
      "Obteniendo IDs de la página 4...\n",
      "Obteniendo IDs de la página 5...\n",
      "Obteniendo IDs de la página 6...\n",
      "Obteniendo IDs de la página 7...\n",
      "Obteniendo IDs de la página 8...\n",
      "Obteniendo IDs de la página 9...\n",
      "No se encontraron IDs en la página 9. Terminando la recolección.\n",
      "Se guardaron 263 IDs de productos en 'ids.json'.\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://www.amazon.es/s?k=\"\n",
    "API_KEY = '1d8a83a5b3d3bfb0e635d9319bf08dd0'\n",
    "QUERY = 'moviles'\n",
    "url_base = BASE_URL + QUERY\n",
    "page_number = 1\n",
    "ids_productos = set() \n",
    "\n",
    "while True:\n",
    "    print(f\"Obteniendo IDs de la página {page_number}...\")\n",
    "    url_pagina = f\"{url_base}&page={page_number}\"\n",
    "    soup = obtener_soup(API_KEY, url_pagina)\n",
    "    \n",
    "    if soup == None: break\n",
    "\n",
    "    ids_paguina = obtener_ids(soup)\n",
    "    if not ids_paguina:\n",
    "        print(f\"No se encontraron IDs en la página {page_number}. Terminando la recolección.\")\n",
    "        break\n",
    "    ids_productos.update(ids_paguina)\n",
    "    page_number += 1\n",
    "\n",
    "fichero = \"../res/ids.json\"\n",
    "with open(fichero, \"w\") as f:\n",
    "    json.dump(list(ids_productos), f, indent=4)\n",
    "print(f\"Se guardaron {len(ids_productos)} IDs de productos en 'ids.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Que pueda funcionar con varias busquedas i despues lo guarde en el json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projecte01_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
